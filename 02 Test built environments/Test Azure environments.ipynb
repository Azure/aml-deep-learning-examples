{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Docker environments\n",
    "\n",
    "After having created the two Docker environments, you will perform a simple test to attest these Docker images can be spawned on an AML compute node. You will execute a simple python script that returns basic diagnostic values.\n",
    "\n",
    "In production, you should considerr an automated build/test pipeline.\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal of this notebook is two-fold:\n",
    "1. Test the successful creation of your Docker environments\n",
    "2. Demonstrate how to run a python script in your newly created Docker environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 | Create a compute target and check install\n",
    "These cells are a pre-flight check to ensure that you've got the necessary requirements accessible and that a compute cluster exists. Like the subsequent notebooks, this is intende to be run on an AzureML compute instance.\n",
    "\n",
    "You will create a new cluster named `testcluster` composed of up to 2 nodes of `Standard_NC4as_T4_v3`. These settings will be stored in a dictionary called `config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "workspace = azureml.core.Workspace.from_config()\n",
    "\n",
    "config = {}\n",
    "config[\"compute_size\"] = \"STANDARD_NC4AS_T4_v3\"\n",
    "config[\"compute_target\"] = \"testcluster\"\n",
    "config[\"compute_node_count\"] = 2\n",
    "config[\"pytorch_configuration\"] = {\n",
    "    \"node_count\": 2, # num of computers in cluster\n",
    "    \"process_count\": 2} # gpus-per-computer * node_count\n",
    "config[\"training_command\"] = \"python diagnose_environment.py\"\n",
    "config[\"experiment\"] = \"Testing_Axolotl_images\"\n",
    "config[\"source_directory\"] = \"src\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute cluster\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cluster = azureml.core.compute.ComputeTarget(\n",
    "        workspace=workspace, \n",
    "        name=config['compute_target']\n",
    "    )\n",
    "    print('Found existing compute cluster')\n",
    "except azureml.core.compute_target.ComputeTargetException:\n",
    "    compute_config = azureml.core.compute.AmlCompute.provisioning_configuration(\n",
    "        vm_size=config['compute_size'],\n",
    "        max_nodes=config['compute_node_count']\n",
    "    )\n",
    "    cluster = azureml.core.compute.ComputeTarget.create(\n",
    "        workspace=workspace,\n",
    "        name=config['compute_target'], \n",
    "        provisioning_configuration=compute_config\n",
    "    )\n",
    "    \n",
    "cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 | Running the Diagnostics on both environments, in sequence\n",
    "\n",
    "In this step, you will retrieve the environments you have created in the previous notebook. You will then submit 2 jobs - one after the other - running the same command in both. The only difference is the environment.\n",
    "You can observe the output of these commands in the AzureML UI for ease of evluation. You could also retrieve the output from the SDK or the CLI.\n",
    "\n",
    "Connect to (or create) the experiment that will host the training run we'll launch. A single experiment can host many runs, each exploring a different set of parameters, architecture, or other approach to a the same problem. Metrics from multiple runs within a single experiment can be plotted against each other in AzureML studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = azureml.core.Experiment(workspace, config['experiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each environment, create a `ScriptRunConfig` object that determines what should be executed (in our case, `src/diagnost_environment.py`) and submit it as an Experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View run details:\n",
      "https://ml.azure.com/runs/Testing_Axolotl_images_1712558447_66de1842?wsid=/subscriptions/68092087-0161-4fb5-b51d-32f18ac56bf9/resourcegroups/aml-au/workspaces/aml-au&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n",
      "View run details:\n",
      "https://ml.azure.com/runs/Testing_Axolotl_images_1712558451_bcfb4583?wsid=/subscriptions/68092087-0161-4fb5-b51d-32f18ac56bf9/resourcegroups/aml-au/workspaces/aml-au&tid=16b3c013-d300-468d-ac64-7eda0820b6d3\n"
     ]
    }
   ],
   "source": [
    "environments = [\"axolotl_gold\", \"axolotl_acpt\"]\n",
    "for environment in environments:\n",
    "    distributed_job_config = azureml.core.runconfig.PyTorchConfiguration(**config['pytorch_configuration'])\n",
    "    aml_config = azureml.core.ScriptRunConfig(\n",
    "                source_directory=config['source_directory'],\n",
    "                command=config['training_command'],\n",
    "                environment=azureml.core.Environment.get(workspace, name=environment),\n",
    "                compute_target=config['compute_target'],\n",
    "                distributed_job_config=distributed_job_config,\n",
    "        )\n",
    "    run = experiment.submit(aml_config)\n",
    "    run.set_tags({\n",
    "        \"environment\":environment\n",
    "    })\n",
    "\n",
    "    print(f\"View run details:\\n{run.get_portal_url()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
