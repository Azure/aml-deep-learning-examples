{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Docker environments\n",
    "\n",
    "After having created the two Docker environments, you will perform a simple test to attest these Docker images can be spawned on an AML compute node. You will execute a simple python script that returns basic diagnostic values.\n",
    "\n",
    "In production, you should considerr an automated build/test pipeline.\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal of this notebook is two-fold:\n",
    "1. Test the successful creation of your Docker environments\n",
    "2. Demonstrate how to run a python script in your newly created Docker environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 | Create a compute target and check install\n",
    "These cells are a pre-flight check to ensure that you've got the necessary requirements accessible and that a compute cluster exists. Like the subsequent notebooks, this is intende to be run on an AzureML compute instance.\n",
    "\n",
    "You will create a new cluster named `testcluster` composed of up to 2 nodes of `Standard_NC4as_T4_v3`. These settings will be stored in a dictionary called `config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "workspace = azureml.core.Workspace.from_config()\n",
    "\n",
    "config = {}\n",
    "config[\"compute_size\"] = \"STANDARD_NC4AS_T4_v3\"\n",
    "config[\"compute_target\"] = \"testcluster\"\n",
    "config[\"compute_node_count\"] = 2\n",
    "config[\"pytorch_configuration\"] = {\n",
    "    \"node_count\": 2, # num of computers in cluster\n",
    "    \"process_count\": 2} # gpus-per-computer * node_count\n",
    "config[\"training_command\"] = \"python diagnose_environments.py\"\n",
    "config[\"experiment\"] = \"Testing_Axolotl_images\"\n",
    "config[\"source_directory\"] = \"src\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute cluster\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cluster = azureml.core.compute.ComputeTarget(\n",
    "        workspace=workspace, \n",
    "        name=config['compute_target']\n",
    "    )\n",
    "    print('Found existing compute cluster')\n",
    "except azureml.core.compute_target.ComputeTargetException:\n",
    "    compute_config = azureml.core.compute.AmlCompute.provisioning_configuration(\n",
    "        vm_size=config['compute_size'],\n",
    "        max_nodes=config['compute_node_count']\n",
    "    )\n",
    "    cluster = azureml.core.compute.ComputeTarget.create(\n",
    "        workspace=workspace,\n",
    "        name=config['compute_target'], \n",
    "        provisioning_configuration=compute_config\n",
    "    )\n",
    "    \n",
    "cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 | Running the Diagnostics on both environments, in sequence\n",
    "\n",
    "In this step, you will retrieve the environments you have created in the previous notebook. You will then submit 2 jobs - one after the other - running the same command in both. The only difference is the environment.\n",
    "You can observe the output of these commands in the AzureML UI for ease of evluation. You could also retrieve the output from the SDK or the CLI.\n",
    "\n",
    "Connect to (or create) the experiment that will host the training run we'll launch. A single experiment can host many runs, each exploring a different set of parameters, architecture, or other approach to a the same problem. Metrics from multiple runs within a single experiment can be plotted against each other in AzureML studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = azureml.core.Experiment(workspace, config['experiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each environment, create a `ScriptRunConfig` object that determines what should be executed (in our case, `src/diagnost_environment.py`) and submit it as an Experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'docker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m environment \u001b[38;5;129;01min\u001b[39;00m environments:\n\u001b[1;32m      3\u001b[0m     distributed_job_config \u001b[38;5;241m=\u001b[39m azureml\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mrunconfig\u001b[38;5;241m.\u001b[39mPyTorchConfiguration(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch_configuration\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m     aml_config \u001b[38;5;241m=\u001b[39m \u001b[43mazureml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScriptRunConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43msource_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource_directory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcommand\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining_command\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcompute_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcompute_target\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdistributed_job_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributed_job_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     run \u001b[38;5;241m=\u001b[39m experiment\u001b[38;5;241m.\u001b[39msubmit(aml_config)\n\u001b[1;32m     12\u001b[0m     run\u001b[38;5;241m.\u001b[39mset_tags({\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment\u001b[39m\u001b[38;5;124m\"\u001b[39m:environment\n\u001b[1;32m     14\u001b[0m     })\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azureml/core/_experiment_method.py:104\u001b[0m, in \u001b[0;36mexperiment_method.<locals>.real_decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m:param init_func:\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m:type init_func: object\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m:rtype: object\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m ExperimentSubmitRegistrar\u001b[38;5;241m.\u001b[39mregister_submit_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, submit_function)\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/azureml/core/script_run_config.py:438\u001b[0m, in \u001b[0;36mScriptRunConfig.__init__\u001b[0;34m(self, source_directory, script, arguments, run_config, _telemetry_values, compute_target, environment, distributed_job_config, resume_from, max_run_duration_seconds, command, docker_runtime_config)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m RunConfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocker_runtime_config\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDockerConfiguration\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m                                             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mdocker \u001b[38;5;241m=\u001b[39m docker_runtime_config\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m environment \u001b[38;5;129;01mand\u001b[39;00m \u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocker\u001b[49m:\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;66;03m# Docker configuration in run config is higher priority than docker settings\u001b[39;00m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;66;03m# in environment docker section, explicitly assign the setting values here\u001b[39;00m\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;66;03m# to keep backward compatibility.\u001b[39;00m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_config\u001b[38;5;241m.\u001b[39mdocker \u001b[38;5;241m=\u001b[39m DockerConfiguration(\n\u001b[1;32m    443\u001b[0m             use_docker\u001b[38;5;241m=\u001b[39menvironment\u001b[38;5;241m.\u001b[39mdocker\u001b[38;5;241m.\u001b[39m_enabled,\n\u001b[1;32m    444\u001b[0m             shm_size\u001b[38;5;241m=\u001b[39menvironment\u001b[38;5;241m.\u001b[39mdocker\u001b[38;5;241m.\u001b[39m_shm_size,\n\u001b[1;32m    445\u001b[0m             shared_volumes\u001b[38;5;241m=\u001b[39menvironment\u001b[38;5;241m.\u001b[39mdocker\u001b[38;5;241m.\u001b[39m_shared_volumes,\n\u001b[1;32m    446\u001b[0m             arguments\u001b[38;5;241m=\u001b[39menvironment\u001b[38;5;241m.\u001b[39mdocker\u001b[38;5;241m.\u001b[39m_arguments)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resume_from:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'docker'"
     ]
    }
   ],
   "source": [
    "environments = [\"axolotl_gold\", \"axolotl_acpt\"]\n",
    "for environment in environments:\n",
    "    distributed_job_config = azureml.core.runconfig.PyTorchConfiguration(**config['pytorch_configuration'])\n",
    "    aml_config = azureml.core.ScriptRunConfig(\n",
    "                source_directory=config['source_directory'],\n",
    "                command=config['training_command'],\n",
    "                environment=azureml.core.Environment.get(workspace, name=environment),\n",
    "                compute_target=config['compute_target'],\n",
    "                distributed_job_config=distributed_job_config,\n",
    "        )\n",
    "    run = experiment.submit(aml_config)\n",
    "    run.set_tags({\n",
    "        \"environment\":environment\n",
    "    })\n",
    "\n",
    "    print(f\"View run details:\\n{run.get_portal_url()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
