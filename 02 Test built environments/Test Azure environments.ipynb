{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Docker environments\n",
    "\n",
    "After having created the two Docker environments, you will perform a simple test to attest these Docker images can be spawned on an AML compute node. You will execute a simple python script that returns basic diagnostic values.\n",
    "\n",
    "In production, you should considerr an automated build/test pipeline.\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal of this notebook is two-fold:\n",
    "1. Test the successful creation of your Docker environments\n",
    "2. Demonstrate how to run a python script in your newly created Docker environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 | Create a compute target and check install\n",
    "These cells are a pre-flight check to ensure that you've got the necessary requirements accessible and that a compute cluster exists. Like the subsequent notebooks, this is intende to be run on an AzureML compute instance.\n",
    "\n",
    "You will create a new cluster named `testcluster` composed of up to 2 nodes of `Standard_NC4as_T4_v3`. These settings will be stored in a dictionary called `config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "workspace = azureml.core.Workspace.from_config()\n",
    "\n",
    "config = {}\n",
    "config[\"compute_size\"] = \"STANDARD_NC4AS_T4_v3\"\n",
    "config[\"compute_target\"] = \"testcluster\"\n",
    "config[\"compute_node_count\"] = 2\n",
    "config[\"pytorch_configuration\"] = {\n",
    "    \"node_count\": 2, # num of computers in cluster\n",
    "    \"process_count\": 2} # gpus-per-computer * node_count\n",
    "config[\"training_command\"] = \"python diagnose_environment.py\"\n",
    "config[\"experiment\"] = \"Testing_Axolotl_images\"\n",
    "config[\"source_directory\"] = \"src\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cluster = azureml.core.compute.ComputeTarget(\n",
    "        workspace=workspace, \n",
    "        name=config['compute_target']\n",
    "    )\n",
    "    print('Found existing compute cluster')\n",
    "except azureml.core.compute_target.ComputeTargetException:\n",
    "    compute_config = azureml.core.compute.AmlCompute.provisioning_configuration(\n",
    "        vm_size=config['compute_size'],\n",
    "        max_nodes=config['compute_node_count']\n",
    "    )\n",
    "    cluster = azureml.core.compute.ComputeTarget.create(\n",
    "        workspace=workspace,\n",
    "        name=config['compute_target'], \n",
    "        provisioning_configuration=compute_config\n",
    "    )\n",
    "    \n",
    "cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 | Running the Diagnostics on both environments, in sequence\n",
    "\n",
    "In this step, you will retrieve the environments you have created in the previous notebook. You will then submit 2 jobs - one after the other - running the same command in both. The only difference is the environment.\n",
    "You can observe the output of these commands in the AzureML UI for ease of evluation. You could also retrieve the output from the SDK or the CLI.\n",
    "\n",
    "Connect to (or create) the experiment that will host the training run we'll launch. A single experiment can host many runs, each exploring a different set of parameters, architecture, or other approach to a the same problem. Metrics from multiple runs within a single experiment can be plotted against each other in AzureML studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = azureml.core.Experiment(workspace, config['experiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each environment, create a `ScriptRunConfig` object that determines what should be executed (in our case, `src/diagnost_environment.py`) and submit it as an Experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environments = [\"axolotl_gold\", \"axolotl_acpt\"]\n",
    "for environment in environments:\n",
    "    distributed_job_config = azureml.core.runconfig.PyTorchConfiguration(**config['pytorch_configuration'])\n",
    "    aml_config = azureml.core.ScriptRunConfig(\n",
    "                source_directory=config['source_directory'],\n",
    "                command=config['training_command'],\n",
    "                environment=azureml.core.Environment.get(workspace, name=environment),\n",
    "                compute_target=config['compute_target'],\n",
    "                distributed_job_config=distributed_job_config,\n",
    "        )\n",
    "    run = experiment.submit(aml_config)\n",
    "    run.set_tags({\n",
    "        \"environment\":environment\n",
    "    })\n",
    "\n",
    "    print(f\"View run details:\\n{run.get_portal_url()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes this notebook. By executing the steps above, you have submitted two jobs to a cluster composed of 2 nodes. The difference between both jobs is that one of them uses a gold image `axolotl_gold`, while the other uses an image based on ACPT `axolotl_acpt`.\n",
    "\n",
    "The 2nd image ships with Nebula, while the first does not.\n",
    "\n",
    "When you submitted each job, it was executed across all nodes in the cluster. This means that you will find 2 std_out in the logs of the job. The image below shows the output of running the gold image diagnostic.\n",
    "\n",
    "![Logs of one of the jobs](img/axolotl_gold.png)\n",
    "\n",
    "This one demonstrates the outcome of the 2nd image diagnostics. The Axolotl_ACPT job differs by having Nebula loaded:\n",
    "![Logs of one of the jobs](img/axolotl_acpt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
