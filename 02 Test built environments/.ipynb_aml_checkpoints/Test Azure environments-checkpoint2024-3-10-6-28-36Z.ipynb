{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Docker environments\n",
    "\n",
    "After having created the curated Azure environment, you will perform a simple test to attest the Docker image can be spawned on an AML compute node. You will execute a simple python script that returns basic diagnostic values.\n",
    "In production, you should consider an automated build/test pipeline.\n",
    "\n",
    "## Goal\n",
    "\n",
    "The goal of this notebook is:\n",
    "1. Demonstrate one way to create a new compute cluster, using the SDK\n",
    "2. Test the successful creation of your Docker environments\n",
    "3. Demonstrate how to run a python script in your newly created Docker environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 | Create a compute target and check install\n",
    "These cells are a pre-flight check to ensure that you've got the necessary requirements accessible and that a compute cluster exists. Like the subsequent notebooks, this is intended to be run on an AzureML compute instance.\n",
    "\n",
    "You will create a new cluster named `testcluster` composed of up to 2 nodes of `Standard_NC4as_T4_v3`. These settings will be stored in a dictionary called `config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "workspace = azureml.core.Workspace.from_config()\n",
    "\n",
    "config = {}\n",
    "config[\"compute_size\"] = \"STANDARD_NC4AS_T4_v3\"\n",
    "config[\"compute_target\"] = \"testcluster\"\n",
    "config[\"compute_node_count\"] = 2\n",
    "config[\"pytorch_configuration\"] = {\n",
    "    \"node_count\": 2, # num of computers in cluster\n",
    "    \"process_count\": 2} # gpus-per-computer * node_count\n",
    "config[\"training_command\"] = \"python diagnose_environment.py\"\n",
    "config[\"experiment\"] = \"Testing_Axolotl_images\"\n",
    "config[\"source_directory\"] = \"src\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cluster = azureml.core.compute.ComputeTarget(\n",
    "        workspace=workspace, \n",
    "        name=config['compute_target']\n",
    "    )\n",
    "    print('Found existing compute cluster')\n",
    "except azureml.core.compute_target.ComputeTargetException:\n",
    "    compute_config = azureml.core.compute.AmlCompute.provisioning_configuration(\n",
    "        vm_size=config['compute_size'],\n",
    "        max_nodes=config['compute_node_count']\n",
    "    )\n",
    "    cluster = azureml.core.compute.ComputeTarget.create(\n",
    "        workspace=workspace,\n",
    "        name=config['compute_target'], \n",
    "        provisioning_configuration=compute_config\n",
    "    )\n",
    "    \n",
    "cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 | Running the Diagnostics on both environments, in sequence\n",
    "\n",
    "In this step, you will retrieve the environment you have created in the previous notebook. You will then submit a job on the cluster you created above.\n",
    "You can observe the output of the job in the AzureML UI for ease of evaluation. You could also retrieve the output from the SDK or the CLI.\n",
    "\n",
    "Connect to (or create) the experiment that will host the training run we'll launch. A single experiment can host many runs, each exploring a different set of parameters, architecture, or other approach to a the same problem. Metrics from multiple runs within a single experiment can be plotted against each other in AzureML studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = azureml.core.Experiment(workspace, config['experiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit a job to AzureML by creating a `ScriptRunConfig` object that determines what should be executed (in our case, `src/diagnose_environment.py`) and submit it as an Experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = \"axolotl_acpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will specify a distributed job configuration. When submitting a job to AzureML on a compute cluster, you ospecify node counts and process counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed_job_config = azureml.core.runconfig.PyTorchConfiguration(**config['pytorch_configuration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_config = azureml.core.ScriptRunConfig(\n",
    "            source_directory=config['source_directory'],\n",
    "            command=config['training_command'],\n",
    "            environment=azureml.core.Environment.get(workspace, name=environment),\n",
    "            compute_target=config['compute_target'],\n",
    "            distributed_job_config=distributed_job_config,\n",
    "    )\n",
    "run = experiment.submit(aml_config)\n",
    "run.set_tags({\n",
    "    \"environment\":environment\n",
    "})\n",
    "\n",
    "print(f\"View run details:\\n{run.get_portal_url()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes this notebook. By executing the steps above, you have submitted a job to a cluster composed of 2 nodes.\n",
    "\n",
    "The image is based on ACPT, and therefore contains Nebula.\n",
    "\n",
    "When you submitted the job, it was executed across all nodes in the cluster. This means that you will find 2 std_out in the logs of the job. The image below shows the output of running the image diagnostic job.\n",
    "\n",
    "This one demonstrates the outcome of the image diagnostics. The Axolotl_ACPT job differs by having Nebula loaded:\n",
    "![Logs of one of the jobs](img/axolotl_acpt.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
